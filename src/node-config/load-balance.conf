# This configures a load balancer to evenly distribute traffic.
#
# More information about the configuration options is available on 
#   * the English wiki - http://wiki.nginx.org/Main

worker_processes  3; # How about one for each backend
#error_log         /var/log/nginx/error.log;

events {
    worker_connections  1024;
}

http {

  # Point the load balancer at three of our app servers.
  # Send traffic to all of them:
  #
  #  - When the server fails 2x in a 5 sec window, stop sending traffic
  #    to that app server.
  #
  upstream distrivia {
    # Use ip_hash to send same client-ip back to same server over and over
    ip_hash;
    server ec2-50-16-110-52.compute-1.amazonaws.com   max_fails=2 fail_timeout=5s;
    server ec2-184-73-37-124.compute-1.amazonaws.com  max_fails=2 fail_timeout=5s;
    server ec2-50-17-133-27.compute-1.amazonaws.com   max_fails=2 fail_timeout=5s;
  }

  #
  # The server defines which requests we will respond to:
  #
  server {
    listen 80;
    server_name "_"; # Respond to any server name
    location / {
      # Should always point to the upstream we define above
      proxy_pass http://distrivia; 
    }
  }
}
